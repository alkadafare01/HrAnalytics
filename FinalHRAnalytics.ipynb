{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mighty-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "offensive-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funded-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load housing data\n",
    "TrainData = pd.read_csv(\"train.csv\")\n",
    "TestData = pd.read_csv(\"test.csv\")\n",
    "Sample=pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spatial-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = pd.get_dummies(TrainData, \n",
    "                     columns = ['department','education','gender','recruitment_channel'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = pd.get_dummies(TrainData, \n",
    "                     columns = ['region'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "oriented-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData['avg_training_score_log'] = np.log(TrainData['avg_training_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "criminal-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData['age_log'] = np.log(TrainData['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "warming-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TrainData[\"previous_year_rating\"]=TrainData[\"previous_year_rating\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "romance-knitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                     0\n",
       "no_of_trainings                 0\n",
       "age                             0\n",
       "previous_year_rating            0\n",
       "length_of_service               0\n",
       "KPIs_met >80%                   0\n",
       "awards_won?                     0\n",
       "avg_training_score              0\n",
       "is_promoted                     0\n",
       "department_Finance              0\n",
       "department_HR                   0\n",
       "department_Legal                0\n",
       "department_Operations           0\n",
       "department_Procurement          0\n",
       "department_R&D                  0\n",
       "department_Sales & Marketing    0\n",
       "department_Technology           0\n",
       "education_Below Secondary       0\n",
       "education_Master's & above      0\n",
       "gender_m                        0\n",
       "recruitment_channel_referred    0\n",
       "recruitment_channel_sourcing    0\n",
       "region_region_10                0\n",
       "region_region_11                0\n",
       "region_region_12                0\n",
       "region_region_13                0\n",
       "region_region_14                0\n",
       "region_region_15                0\n",
       "region_region_16                0\n",
       "region_region_17                0\n",
       "region_region_18                0\n",
       "region_region_19                0\n",
       "region_region_2                 0\n",
       "region_region_20                0\n",
       "region_region_21                0\n",
       "region_region_22                0\n",
       "region_region_23                0\n",
       "region_region_24                0\n",
       "region_region_25                0\n",
       "region_region_26                0\n",
       "region_region_27                0\n",
       "region_region_28                0\n",
       "region_region_29                0\n",
       "region_region_3                 0\n",
       "region_region_30                0\n",
       "region_region_31                0\n",
       "region_region_32                0\n",
       "region_region_33                0\n",
       "region_region_34                0\n",
       "region_region_4                 0\n",
       "region_region_5                 0\n",
       "region_region_6                 0\n",
       "region_region_7                 0\n",
       "region_region_8                 0\n",
       "region_region_9                 0\n",
       "avg_training_score_log          0\n",
       "age_log                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "according-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 57)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coated-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=TrainData.drop(['employee_id','avg_training_score','age','is_promoted'] ,axis=1)\n",
    "y=TrainData['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifth-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "challenging-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "overall-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "difficult-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "sc=RobustScaler() \n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "backed-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler() \n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "boring-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit logistics Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "marked-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a\\cc\\ana\\envs\\insurance\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:47:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/gbm/gbtree.cc:81: DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using `tree_method` parameter instead.\n",
      "[19:47:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 93.05%\n",
      "ROCAUC score: %.2f%% 0.7105784848894775\n",
      "F1 score: 0.5189393939393939\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model=XGBClassifier( learning_rate =0.1, n_estimators=494, max_depth=5,subsample = 0.70, \n",
    "                                                              scale_pos_weight = 2.5,updater =\"grow_histmaker\",base_score  = 0.2,\n",
    "                                                              )\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#accuracy_score(X_train, y_train)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, y_pred))\n",
    "print('F1 score:',f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adapted-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a\\cc\\ana\\envs\\insurance\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 93.36%\n",
      "ROCAUC score: %.2f%% 0.7063544354141504\n",
      "F1 score: 0.5229357798165137\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model3=XGBClassifier(base_score=0.5, gamma=0.03, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "        missing=None, n_estimators=494, nthread=15,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=2.5,  silent=True, subsample=1 )\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred = model3.predict(X_test)\n",
    "#accuracy_score(X_train, y_train)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, y_pred))\n",
    "print('F1 score:',f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "emotional-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a\\cc\\ana\\envs\\insurance\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:46:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 92.70%\n",
      "ROCAUC score: %.2f%% 0.7085982357948886\n",
      "F1 score: 0.5073891625615763\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model2=XGBClassifier( learning_rate=0.1, n_estimators=494, max_depth=5, subsample=0.8,\n",
    "                         scale_pos_weight=2.5,min_child_weight=7, gamma=0.4, nthread=4,  \n",
    "                         colsample_bytree=0.8)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "#accuracy_score(X_train, y_train)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, y_pred))\n",
    "print('F1 score:',f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "simple-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942 (0.002)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "modellgb = LGBMClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(modellgb, X, y, scoring='accuracy', cv=cv, n_jobs=1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "three-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellgb1 = LGBMClassifier(boosting_type='dart',\n",
    "                       max_depth=5, scale_pos_weight=2.5,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=5000,\n",
    "                        min_child_weight=0.01,\n",
    "                        colsample_bytree=0.5,\n",
    "                       random_state=1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "square-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Accuracy: 92.92%\n",
      "ROCAUC score: %.2f%% 0.7045530016241313\n",
      "F1 score: 0.5084459459459459\n"
     ]
    }
   ],
   "source": [
    "modellgb1.fit(X_train, y_train)\n",
    "yhat = modellgb1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, yhat))\n",
    "print('F1 score:',f1_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cardiac-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellgb2 = LGBMClassifier(subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1, max_bin = 60,num_leaves = 300,boosting_type = 'dart',learning_rate=0.15, n_estimators=494, max_depth=5, scale_pos_weight=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "tight-notice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.55%\n",
      "ROCAUC score: %.2f%% 0.703748483037186\n",
      "F1 score: 0.5263628239499554\n"
     ]
    }
   ],
   "source": [
    "modellgb2.fit(X_train, y_train)\n",
    "yhat = modellgb2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, yhat))\n",
    "print('F1 score:',f1_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "greek-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellgb3 = LGBMClassifier(bagging_fraction=0.9, feature_fraction=0.9, subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1, max_bin = 60,num_leaves = 300,boosting_type = 'dart',learning_rate=0.15, n_estimators=494, max_depth=5, scale_pos_weight=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fluid-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Accuracy: 94.03%\n",
      "ROCAUC score: %.2f%% 0.7046153117495142\n",
      "F1 score: 0.5426573426573428\n"
     ]
    }
   ],
   "source": [
    "modellgb3.fit(X_train, y_train)\n",
    "yhat = modellgb3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, yhat))\n",
    "print('F1 score:',f1_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "compliant-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"binary\",\n",
    "       \"n_estimators\":10000,\n",
    "       \"reg_alpha\" : 0.1,\n",
    "       \"reg_lambda\":0.1,\n",
    "       \"n_jobs\":-1,\n",
    "       \"colsample_bytree\":.8,\n",
    "       \"min_child_weight\":8,\n",
    "       \"subsample\":0.8715623,\n",
    "       \"min_data_in_leaf\":100,\n",
    "       \"nthread\":4,\n",
    "       \"metric\" : \"f1\",\n",
    "       \"num_leaves\" : 600,\n",
    "       \"learning_rate\" : 0.01,\n",
    "       \"verbosity\" : -1,\n",
    "       \"seed\": 120,\n",
    "       \"max_bin\":60,\n",
    "       'max_depth':15,\n",
    "       'min_gain_to_split':.0222415,\n",
    "       'scale_pos_weight':2\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "objective-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.55%\n",
      "ROCAUC score: %.2f%% 0.7025580511073188\n",
      "F1 score: 0.5246636771300448\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('ROCAUC score: %.2f%%',roc_auc_score(y_test, yhat))\n",
    "print('F1 score:',f1_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "built-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "alpha-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(X_train, X_test, y_train, y_test, test_df):\n",
    "    params = {\n",
    "        \"objective\" : \"binary\",\n",
    "       \"n_estimators\":10000,\n",
    "       \"reg_alpha\" : 0.1,\n",
    "       \"reg_lambda\":0.1,\n",
    "       \"n_jobs\":-1,\n",
    "       \"colsample_bytree\":.8,\n",
    "       \"min_child_weight\":8,\n",
    "       \"subsample\":0.8715623,\n",
    "       \"min_data_in_leaf\":100,\n",
    "       \"nthread\":4,\n",
    "       \"metric\" : \"f1\",\n",
    "       \"num_leaves\" : 600,\n",
    "       \"learning_rate\" : 0.01,\n",
    "       \"verbosity\" : -1,\n",
    "       \"seed\": 120,\n",
    "       \"max_bin\":60,\n",
    "       'max_depth':15,\n",
    "       'min_gain_to_split':.0222415,\n",
    "       'scale_pos_weight':2\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    lgval = lgb.Dataset(X_test, label=y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 10000, \n",
    "                      valid_sets=[lgtrain, lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=100, \n",
    "                      evals_result=evals_result,feval=lgb_f1_score)\n",
    "    \n",
    "    pred_test_y = model.predict(test_df, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "lasting-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a\\cc\\ana\\envs\\insurance\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with nthread=4, will be overridden by n_jobs=-1. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's f1: 0.379784\tvalid_1's f1: 0.363956\n",
      "[200]\ttraining's f1: 0.482466\tvalid_1's f1: 0.487058\n",
      "[300]\ttraining's f1: 0.52387\tvalid_1's f1: 0.50076\n",
      "[400]\ttraining's f1: 0.550444\tvalid_1's f1: 0.511582\n",
      "[500]\ttraining's f1: 0.565931\tvalid_1's f1: 0.518195\n",
      "[600]\ttraining's f1: 0.578222\tvalid_1's f1: 0.520665\n",
      "[700]\ttraining's f1: 0.591877\tvalid_1's f1: 0.519944\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's f1: 0.584921\tvalid_1's f1: 0.521657\n",
      "LightGBM Training Completed...\n"
     ]
    }
   ],
   "source": [
    "pred_test, model, evals_result = run_lgb(X_train, X_test, y_train, y_test, test_df)\n",
    "print(\"LightGBM Training Completed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "quiet-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(pred_test)):\n",
    "    if pred_test[i]>=.5:       # setting threshold to .5\n",
    "       pred_test[i]=1\n",
    "    else:  \n",
    "       pred_test[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "detected-diameter",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d7954f42ef6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFinalTestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_promoted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mFinalTestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_promoted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFinalTestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_promoted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_test' is not defined"
     ]
    }
   ],
   "source": [
    "FinalTestData['is_promoted']= pred_test\n",
    "FinalTestData['is_promoted']=FinalTestData['is_promoted'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "streaming-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTestData = pd.get_dummies(TestData, \n",
    "                     columns = ['department','education','gender','recruitment_channel'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cognitive-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTestData = pd.get_dummies(FinalTestData, \n",
    "                     columns = ['region'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "general-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTestData['avg_training_score_log'] = np.log(FinalTestData['avg_training_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "exact-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTestData['age_log'] = np.log(FinalTestData['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dynamic-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FinalTestData[\"previous_year_rating\"]=FinalTestData[\"previous_year_rating\"].fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "increased-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=FinalTestData.drop(['employee_id','avg_training_score','age'] ,axis=1)\n",
    "\n",
    "test_df=sc.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "optimum-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalTestData['is_promoted']= modellgb3.predict(test_df)\n",
    "FinalTestData['is_promoted']=FinalTestData['is_promoted'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "australian-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>53478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>25600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23487</th>\n",
       "      <td>45409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23489</th>\n",
       "      <td>5973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id  is_promoted\n",
       "23485        53478            0\n",
       "23486        25600            0\n",
       "23487        45409            0\n",
       "23488         1186            0\n",
       "23489         5973            1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = FinalTestData[['employee_id','is_promoted']]\n",
    "\n",
    "submission.to_csv(\"submission_modellgb3.csv\", index=False)\n",
    "\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-small",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
